"""
Security Analysis Agent

Agente que usa LLM para interpretar resultados de an√°lise de seguran√ßa
e gerar relat√≥rios em linguagem natural.
"""

from typing import Dict, Any
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from .base_agent import BaseAgent
import os
from dotenv import load_dotenv
import json

# Carregar vari√°veis de ambiente
load_dotenv()


class SecurityAnalysisAgent(BaseAgent):
    """
    Agente que analisa resultados de seguran√ßa usando LLM.

    Gera:
    - Resumo executivo
    - An√°lise detalhada
    - Recomenda√ß√µes priorizadas
    - Explica√ß√µes em linguagem clara
    """

    def __init__(self):
        super().__init__("SecurityAnalysisAgent")

        self.llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.3,  # Baixa temperatura para an√°lise t√©cnica
            api_key=os.getenv("OPENAI_API_KEY")
        )

        self.analysis_prompt = PromptTemplate(
            template="""Voc√™ √© um especialista em seguran√ßa de websites. Analise os seguintes resultados de uma verifica√ß√£o de seguran√ßa e forne√ßa uma interpreta√ß√£o detalhada.

URL Analisado: {url}
Risk Score: {risk_score}/100
Risk Level: {risk_level}

DADOS DA AN√ÅLISE:
{security_data}

Por favor, forne√ßa:

1. RESUMO EXECUTIVO (2-3 frases)
   - Avalia√ß√£o geral da seguran√ßa do site
   - Principais problemas encontrados

2. AN√ÅLISE DETALHADA
   Por categoria, explique o que foi encontrado e o impacto:
   - Protocolo e SSL/TLS
   - Headers de Seguran√ßa
   - Vulnerabilidades
   - Arquivos Expostos
   - Cookies
   - CMS Detectado

3. PRINCIPAIS RISCOS (ordenados por gravidade)
   Liste os 3-5 riscos mais cr√≠ticos com:
   - Descri√ß√£o do risco
   - Impacto potencial
   - Probabilidade de explora√ß√£o

4. RECOMENDA√á√ïES PRIORIZADAS
   Liste 5-7 a√ß√µes recomendadas em ordem de prioridade:
   - O que fazer
   - Por que √© importante
   - Dificuldade de implementa√ß√£o (F√°cil/M√©dia/Dif√≠cil)

5. PONTOS POSITIVOS
   O que o site est√° fazendo corretamente em termos de seguran√ßa

Seja t√©cnico mas claro. Use emojis quando apropriado (üö®, ‚ö†Ô∏è, ‚úÖ, üîí, etc).
Responda em Portugu√™s de Portugal.""",
            input_variables=["url", "risk_score", "risk_level", "security_data"]
        )

    def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analisa resultados de seguran√ßa usando LLM.

        Args:
            input_data: Dict contendo os resultados do security workflow

        Returns:
            Dict com an√°lise interpretada pelo LLM
        """
        try:
            self.log_action("Iniciando an√°lise com LLM", {})

            # Extrair dados
            url = input_data.get("url", "")
            risk_score = input_data.get("risk_score", 0)
            risk_level = input_data.get("risk_level", "UNKNOWN")

            # Formatar dados para o LLM
            security_data = self._format_security_data(input_data)

            # Criar chain
            chain = self.analysis_prompt | self.llm

            # Executar an√°lise
            response = chain.invoke({
                "url": url,
                "risk_score": risk_score,
                "risk_level": risk_level,
                "security_data": security_data
            })

            analysis_text = response.content

            self.log_action("An√°lise LLM conclu√≠da", {"chars": len(analysis_text)})

            return {
                "llm_analysis": {
                    "status": "‚úÖ An√°lise Completa",
                    "analysis": analysis_text,
                    "url": url,
                    "risk_score": risk_score,
                    "risk_level": risk_level
                }
            }

        except Exception as e:
            self.logger.error(f"Erro na an√°lise LLM: {str(e)}")
            return {
                "llm_analysis": {
                    "status": "‚ùå Erro na an√°lise",
                    "error": str(e)
                }
            }

    def _format_security_data(self, data: Dict[str, Any]) -> str:
        """
        Formata dados de seguran√ßa para o prompt do LLM.

        Args:
            data: Dados brutos do security workflow

        Returns:
            String formatada para o LLM
        """
        formatted = []

        # Protocolo e SSL
        if "security_issues" in data:
            formatted.append("## PROTOCOLO")
            for issue in data["security_issues"]:
                formatted.append(f"- {issue}")

        # SSL Avan√ßado
        if "ssl_advanced" in data:
            ssl = data["ssl_advanced"]
            formatted.append("\n## SSL/TLS")
            formatted.append(f"- Status: {ssl.get('status')}")
            if ssl.get('dias_restantes'):
                formatted.append(f"- Dias at√© expira√ß√£o: {ssl.get('dias_restantes')}")
            if ssl.get('protocolo'):
                formatted.append(f"- Protocolo: {ssl.get('protocolo')}")
            if ssl.get('emissor'):
                formatted.append(f"- Emissor: {ssl.get('emissor')}")
            if ssl.get('issues'):
                for issue in ssl.get('issues', []):
                    formatted.append(f"  - {issue}")
            if ssl.get('info'):
                for info in ssl.get('info', []):
                    formatted.append(f"  - {info}")

        # Headers
        if "headers_check" in data:
            formatted.append("\n## HEADERS DE SEGURAN√áA")
            for header, status in data["headers_check"].items():
                formatted.append(f"- {header}: {status}")

        # Vulnerabilidades
        if "vulnerabilities" in data:
            formatted.append("\n## VULNERABILIDADES")
            for vuln in data["vulnerabilities"]:
                formatted.append(f"- {vuln}")

        # Arquivos Expostos
        if "exposed_files" in data:
            exp = data["exposed_files"]
            formatted.append("\n## ARQUIVOS EXPOSTOS")
            formatted.append(f"- Total de arquivos expostos: {exp.get('total_exposed', 0)}")

            if exp.get('critical_exposed'):
                formatted.append("- CR√çTICOS:")
                for item in exp['critical_exposed']:
                    formatted.append(f"  - {item}")

            if exp.get('warnings'):
                formatted.append(f"- Avisos: {len(exp['warnings'])} itens")

        # Cookies
        if "cookie_security" in data:
            cookies = data["cookie_security"]
            formatted.append("\n## COOKIES")
            formatted.append(f"- Status: {cookies.get('status')}")
            formatted.append(f"- Cookies analisados: {cookies.get('cookies_analyzed', 0)}")
            if cookies.get('issues'):
                for issue in cookies.get('issues', [])[:3]:  # Primeiros 3
                    formatted.append(f"  - {issue}")

        # CMS
        if "cms_detection" in data:
            cms = data["cms_detection"]
            formatted.append("\n## CMS DETECTADO")
            formatted.append(f"- Status: {cms.get('status')}")
            if cms.get('cms'):
                formatted.append(f"- CMS: {cms.get('cms')}")
                if cms.get('version'):
                    formatted.append(f"- Vers√£o: {cms.get('version')}")

        return "\n".join(formatted)
